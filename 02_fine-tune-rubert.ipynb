{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14fROsbtL7wW43XI85YREJT3GtQcMKnq-","timestamp":1679063554309},{"file_id":"1EE2M8zetaba3bNHL1Lm4tRLoexw-GC_x","timestamp":1678982416814}],"mount_file_id":"1BET8rRFRmfwubLzykboXqgIhZmD1Dqww","authorship_tag":"ABX9TyPnCCBrLnHaNpe1/py1DrDD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Info"],"metadata":{"id":"ERJq_MR3O_oP"}},{"cell_type":"markdown","source":["Дообучение (fine-tuning) BERT модели для задачи классификации текстов."],"metadata":{"id":"W3N60KWGQjCs"}},{"cell_type":"markdown","source":["# Settings"],"metadata":{"id":"M63RW4gwvuuq"}},{"cell_type":"code","source":["# Files\n","GDRIVE_DIR = r'/content/drive/MyDrive/DS/20230314_ke-intern-test/'\n","\n","DATASET_DIR = GDRIVE_DIR + 'dataset/'\n","\n","TRAIN_NPZ = GDRIVE_DIR + 'tokens_rubert_train.npz'\n","VAL_NPZ = GDRIVE_DIR + 'tokens_rubert_val.npz'\n","\n","# Model\n","BERT_MODEL_NAME = 'DeepPavlov/rubert-base-cased-sentence'\n","\n","# Output\n","MODELS_DIR = GDRIVE_DIR + 'models/'\n","\n","# Reproducibility\n","SEED = 1"],"metadata":{"id":"ougZJRLYIghS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Init"],"metadata":{"id":"dZ7QdDKXPCNr"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"_8LoVcRTO4Xu"}},{"cell_type":"code","source":["!pip install -q transformers"],"metadata":{"id":"xiGk5vcgTMqC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"vufgOtMHv5BV"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from tqdm.notebook import tqdm\n","\n","import matplotlib.pyplot as plt\n","\n","import torch"],"metadata":{"id":"gyc-Rr7T-KG1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definitions"],"metadata":{"id":"aNpdsbNOoK1S"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","if device.type == 'cuda':\n","    print('GPU:', torch.cuda.get_device_name(0))\n","else:\n","    print('CPU')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTotBDYUAKvC","executionInfo":{"status":"ok","timestamp":1679065905100,"user_tz":-180,"elapsed":534,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"1057d6d0-2984-40f8-bc06-4dcfc127fa20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["#@title  { form-width: \"1px\", display-mode: \"form\" }\n","#@markdown ```python\n","#@markdown class Dataset(inputs)\n","#@markdown ```\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, inputs):\n","        self.inputs = inputs\n","        \n","    def __getitem__(self, idx):\n","        return {k: v[idx] for k, v in self.inputs.items()}\n","    \n","    def __len__(self):\n","        return len(self.inputs['input_ids'])"],"metadata":{"id":"Ez3tlesTaQl0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"IH7bVVJYv8UX"}},{"cell_type":"markdown","source":["## Loading data"],"metadata":{"id":"8YB-OZcxySG2"}},{"cell_type":"code","source":["train_npz = np.load(TRAIN_NPZ)\n","val_npz = np.load(VAL_NPZ)\n","\n","input_ids_train = train_npz['input_ids']\n","labels_train = train_npz['labels']\n","\n","input_ids_val = val_npz['input_ids']\n","labels_val = val_npz['labels']\n","\n","input_ids_train.shape, labels_train.shape, input_ids_val.shape, labels_val.shape"],"metadata":{"id":"m1OGlmDKsNt6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679065906893,"user_tz":-180,"elapsed":1796,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"0743d370-4235-4b83-adee-b63fb02442bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((81120, 300), (81120,), (10000, 300), (10000,))"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Create pytorch datasets\n","PAD_TOKEN_ID = 0\n","\n","train_inputs = {'input_ids': torch.tensor(input_ids_train.astype(np.int32)),\n","                'attention_mask': torch.tensor(input_ids_train != PAD_TOKEN_ID, dtype=torch.uint8),\n","                'labels': torch.tensor(labels_train.astype(np.int64))}\n","                # int64 is required here to convert to torch.long dtype\n","\n","val_inputs = {'input_ids': torch.tensor(input_ids_val.astype(np.int32)),\n","                'attention_mask': torch.tensor(input_ids_val != PAD_TOKEN_ID, dtype=torch.uint8),\n","                'labels': torch.tensor(labels_val.astype(np.int64))}\n","\n","train_ds = Dataset(train_inputs)\n","val_ds = Dataset(val_inputs)\n","\n","train_ds[0]\n","# Example of training sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIhasn5-WRGC","executionInfo":{"status":"ok","timestamp":1679065906895,"user_tz":-180,"elapsed":26,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"b05b4dd2-651c-4a1c-dcff-cad3611492b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([   101,  94934,  31091,  46754,  35127,  48675,  43485,    869,  61248,\n","          33460,  28221,    192,  39362,  31694,  35633,   6301,  54119,  68524,\n","            814,    106,  79588,  32145,    869,  16337,  54384,   3187,  29697,\n","           1703,  82941,  31231,   1706,   1766,  36260,   7993,    114,  72792,\n","            132,  83057,   7471,    851,  19998,   2630,  14269,  24737,  60689,\n","            869,  16337,  54384,   3187,   2068,  34035,   2748,  27339,    128,\n","           4427,  11992,   2190,  39843,    851,  89585,  35260,  21953,    132,\n","            100,  52837,  14444, 112072,   9450,   1469,  10189,  63154,   3521,\n","          16729,  25377,  38156,    128,   1997,  13231,    875,   3660,   6818,\n","           7462,  38741,    866,  16729,    132,   7638,  10271,   3998,   5022,\n","          24856,  89769,    128,   3622,  22571,  45628,   3247,   1516,  45051,\n","            132,   7638,  56861,    128,  13717,  24935,   1516,  46758,    128,\n","          27519,    845,  23844,   5931,  35846,   8568,  13036,    845,   6377,\n","          28338,    132,  12363,  13185,   1758,  89942,   3187,  18216,  16377,\n","            851,   7076,  92213,    869,  35478,    106,  23243,   2924,    156,\n","            847,    132,  30042,    134,  87479,   2630,  30294,    120,  46754,\n","          35127,    122,  13778,  27446,    156,   9931,  12826,   4414,  13778,\n","          27446,    156,  10628,  13057,   4414,  23878,  38991,   1388,    156,\n","           4428,  38991,   1388,  23878,  66122,    156,  29968,  22031,   8835,\n","            156,  12165,    128,  12040,    128,  11638,    128,   7553,    128,\n","          11812,    128,  12037,    102,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0,      0,      0,      0,      0,      0,      0,\n","              0,      0,      0], dtype=torch.int32),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8),\n"," 'labels': tensor(121)}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["num_labels = max(labels_train) + 1\n","num_labels  # число классов для задачи классификации"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"be7YfyhNb6Z_","executionInfo":{"status":"ok","timestamp":1679065906896,"user_tz":-180,"elapsed":20,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"f0249802-c6ea-4494-ccda-e82fafe33ad7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["845"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Language model"],"metadata":{"id":"B67KrJm7yW4g"}},{"cell_type":"code","source":["import transformers\n","from transformers import BertForSequenceClassification, BertTokenizerFast\n","from transformers import TrainingArguments, Trainer"],"metadata":{"id":"XcwYOx5hz2dj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=num_labels).to(device)\n","tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myaBleImy7cv","executionInfo":{"status":"ok","timestamp":1679065926291,"user_tz":-180,"elapsed":16074,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"4893392b-638f-49ff-b5d4-d6bb43992d51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["rows = [[param_name, list(param_tensor.size())]\n","        for param_name, param_tensor in model.named_parameters()]\n","layers = pd.DataFrame(rows, columns='layer_name layer_shape'.split())\n","layers['layer_size'] = layers.layer_shape.map(np.prod)\n","layers  # список слоев модели"],"metadata":{"id":"1pEZ60GGC8G5","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1679065926293,"user_tz":-180,"elapsed":64,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"8d75a0aa-9bca-4d09-e8c0-d73b57f4acce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       layer_name    layer_shape  layer_size\n","0          bert.embeddings.word_embeddings.weight  [119547, 768]    91812096\n","1      bert.embeddings.position_embeddings.weight     [512, 768]      393216\n","2    bert.embeddings.token_type_embeddings.weight       [2, 768]        1536\n","3                bert.embeddings.LayerNorm.weight          [768]         768\n","4                  bert.embeddings.LayerNorm.bias          [768]         768\n","..                                            ...            ...         ...\n","196   bert.encoder.layer.11.output.LayerNorm.bias          [768]         768\n","197                      bert.pooler.dense.weight     [768, 768]      589824\n","198                        bert.pooler.dense.bias          [768]         768\n","199                             classifier.weight     [845, 768]      648960\n","200                               classifier.bias          [845]         845\n","\n","[201 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-6fc89d3d-7b8d-4762-8c3c-447a5ff8fdd0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>layer_name</th>\n","      <th>layer_shape</th>\n","      <th>layer_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bert.embeddings.word_embeddings.weight</td>\n","      <td>[119547, 768]</td>\n","      <td>91812096</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>bert.embeddings.position_embeddings.weight</td>\n","      <td>[512, 768]</td>\n","      <td>393216</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bert.embeddings.token_type_embeddings.weight</td>\n","      <td>[2, 768]</td>\n","      <td>1536</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bert.embeddings.LayerNorm.weight</td>\n","      <td>[768]</td>\n","      <td>768</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>bert.embeddings.LayerNorm.bias</td>\n","      <td>[768]</td>\n","      <td>768</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>bert.encoder.layer.11.output.LayerNorm.bias</td>\n","      <td>[768]</td>\n","      <td>768</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>bert.pooler.dense.weight</td>\n","      <td>[768, 768]</td>\n","      <td>589824</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>bert.pooler.dense.bias</td>\n","      <td>[768]</td>\n","      <td>768</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>classifier.weight</td>\n","      <td>[845, 768]</td>\n","      <td>648960</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>classifier.bias</td>\n","      <td>[845]</td>\n","      <td>845</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>201 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fc89d3d-7b8d-4762-8c3c-447a5ff8fdd0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6fc89d3d-7b8d-4762-8c3c-447a5ff8fdd0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6fc89d3d-7b8d-4762-8c3c-447a5ff8fdd0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"NAu1kC8T-8uA"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score"],"metadata":{"id":"Raa7DHQ-htjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average='weighted')\n","    return {'F1': f1}"],"metadata":{"id":"hXJFuR-Chtsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',         # Выходной каталог\n","    num_train_epochs=3,             # Кол-во эпох для обучения\n","    per_device_train_batch_size=8,  # Размер пакета для каждого устройства во время обучения\n","    per_device_eval_batch_size=8,   # Размер пакета для каждого устройства во время валидации\n","    weight_decay=0.01,              # Понижение весов\n","    logging_dir='./logs',           # Каталог для хранения журналов\n","    load_best_model_at_end=True,    # Загружать ли лучшую модель после обучения\n","    learning_rate=1e-5,             # Скорость обучения\n","    evaluation_strategy='epoch',    # Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n","    logging_strategy='epoch',       # Логирование после каждой эпохи\n","    save_strategy='epoch',          # Сохранение после каждой эпохи\n","    save_total_limit=1,\n","    seed=SEED,\n",")"],"metadata":{"id":"U4JvCf3KhtY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(model=model,\n","                  tokenizer=tokenizer,\n","                  args=training_args,\n","                  train_dataset=train_ds,\n","                  eval_dataset=val_ds,\n","                  compute_metrics=compute_metrics,)"],"metadata":{"id":"jt9HxIdSj0Cw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_output = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"id":"zwlnONUajzxp","executionInfo":{"status":"ok","timestamp":1679081626584,"user_tz":-180,"elapsed":15688558,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"0a227f88-e4f4-4654-be46-486de9d52a6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='30420' max='30420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [30420/30420 4:22:17, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.220500</td>\n","      <td>1.900797</td>\n","      <td>0.631400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.522900</td>\n","      <td>1.281080</td>\n","      <td>0.737314</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.123200</td>\n","      <td>1.147934</td>\n","      <td>0.765561</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["train_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Anm0tDoRCpWr","executionInfo":{"status":"ok","timestamp":1679081631371,"user_tz":-180,"elapsed":461,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"7d1367c4-deb0-4321-8862-b15b4878f711"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=30420, training_loss=1.9555304833888068, metrics={'train_runtime': 15738.3222, 'train_samples_per_second': 15.463, 'train_steps_per_second': 1.933, 'total_flos': 3.7801964113056e+16, 'train_loss': 1.9555304833888068, 'epoch': 3.0})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Batch size selection:\n","\n","# Batch = 16\n","#  Epoch\tTraining Loss\tValidation Loss\tF1\n","#  1\t6.235500\t5.874439\t0.025794\n","#  2\t5.684100\t5.628022\t0.038680\n","\n","# Batch = 8\n","#  Epoch\tTraining Loss\tValidation Loss\tF1\n","#  1\t5.976200\t5.492195\t0.054494\n","#  2\t5.258400\t5.249204\t0.084588"],"metadata":{"id":"GNdvWALZqesl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## https://discuss.pytorch.org/t/how-can-we-release-gpu-memory-cache/14530/28\n","## Release GPU memory:\n","# import gc\n","# globals().pop('model', None)\n","# gc.collect()\n","# torch.cuda.empty_cache()\n","# !nvidia-smi -q -d memory"],"metadata":{"id":"fJ3WCNuarxbD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save model"],"metadata":{"id":"zCNWqnbM-_-D"}},{"cell_type":"code","source":["model_name = 'fine-tune-bert_0_765561'\n","model.save_pretrained(model_name)\n","tokenizer.save_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avcfmKA8q024","executionInfo":{"status":"ok","timestamp":1679081700937,"user_tz":-180,"elapsed":3398,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"outputId":"37aad2be-791e-478c-8917-738d2c92d6ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('fine-tune-bert_0_765561/tokenizer_config.json',\n"," 'fine-tune-bert_0_765561/special_tokens_map.json',\n"," 'fine-tune-bert_0_765561/vocab.txt',\n"," 'fine-tune-bert_0_765561/added_tokens.json',\n"," 'fine-tune-bert_0_765561/tokenizer.json')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["!cp -r {model_name} {MODELS_DIR + model_name}\n","!ls -l {MODELS_DIR}"],"metadata":{"id":"GCtvbC5o3bLz","executionInfo":{"status":"ok","timestamp":1679081720134,"user_tz":-180,"elapsed":3444,"user":{"displayName":"Dmitriy Yudin","userId":"03136177699602668679"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"38b2f140-844b-443e-9044-431109ee1bfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 8\n","drwx------ 2 root root 4096 Mar 17 14:08 fine-tune-bert-0_084588\n","drwx------ 2 root root 4096 Mar 17 19:36 fine-tune-bert_0_765561\n"]}]},{"cell_type":"code","source":["!cp -r logs {GDRIVE_DIR + 'logs/20230317-1'}"],"metadata":{"id":"WnSoVwbF5rBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NA8dcwLV_Hqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R-9IzeVR5q4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"--oPMLPq_hCZ"},"execution_count":null,"outputs":[]}]}